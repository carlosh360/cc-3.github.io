<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="../stylesheets/w3.css">
        <link rel="stylesheet" href="../stylesheets/w3-theme-black.css">
        <link rel="stylesheet" href="http://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css">
        <link rel="icon" href="../images/favicon.png" type="image/x-icon">
        <title>CC3 LAB 7</title>
        <style>
            header {
                background-image: url("../images/header.jpg");
                color: white;
                width:100%;
                min-height:400px;
                max-height:700px;
            }
            .w3-topnav a:first-child:hover{color: #009688;border-bottom: 3px solid transparent;}
        </style>
    </head>
    <body class="w3-light-grey">
        <nav class="w3-topnav w3-center w3-theme w3-card-4 w3-top">
              <a href="../index.html" title="HOME"><i class="fa fa-home w3-large"></i></a>
        </nav>
        <header id="header" class="w3-container w3-card-4 w3-padding-32">
            <div class="w3-center w3-padding-32">
                <div class="w3-center">
                    <h1 class="w3-jumbo">CC3 Estructura de Máquinas</h1>
                    <h1 class="w3-jumbo w3-animate-bottom">Laboratorio 7</h1>
                    <h4 class="w3-xxlarge">MapReduce, Hadoop, y Spark</h4>
                </div>
            </div>
        </header>
        <div class="w3-container w3-margin-16">
            <h1 id="notas" class="w3-card-24 w3-theme w3-round-large w3-padding-left w3-card-4">Objetivos</h1>
            <div class="w3-card-24 w3-white w3-padding-8 w3-round-large">
                <p class="w3-text w3-justify w3-large w3-margin-16">
                    <ul>
                        <li class="w3-large">Ganar experiencia corriendo MapReduce y ganar entendimiento en el paradigma MapReduce.</li>
                        <li class="w3-large">Quedar más familiarizado con Apache Spark y ganar experiencia corriendo Spark local.</li>
                        <li class="w3-large">Aprender como aplicar MapReduce en Spark implementando algunos problemas/algoritmos en Spark.</li>
                    </ul>
                </p>
            </div>
            <h1 id="notas" class="w3-card-24 w3-theme w3-round-large w3-padding-left w3-card-4">Setup</h1>
            <div class="w3-card-24 w3-white w3-padding-8 w3-round-large">
                <p class="w3-text w3-justify w3-large w3-margin-16">
                    Descarguen los archivos necesarios para este laboratorio en el siguiente <a href="#" target="_blank"><span class="w3-btn w3-red w3-round w3-medium">link</link></a>
                </p>
            </div>
            <h1 id="notas" class="w3-card-24 w3-theme w3-round-large w3-padding-left w3-card-4">Información</h1>
            <div class="w3-card-24 w3-white w3-padding-8 w3-round-large">
                <p class="w3-text w3-justify w3-large w3-margin-16">
                    En las clases les hemos mostrado el “cluster computing” (particularmente, MapReduce), como se prepara y se ejecuta, pero ahora es la hora de ganar experiencia haciendo y corriendo programas hechos en un framework que soporta “cluster computing”.
                    <br><br>
                    En este laboratorio, los vamos a introducir a dos diferentes frameworks de cluster computing:
                    <ul>
                        <li class="w3-large">El primero es Hadoop – donde van a correr las rutinas Map y Reduce localmente</li>
                        <li class="w3-large">El segundo es Spark – donde van a traducir lo hecho con Hadoop para que corra en Spark</li>
                    </ul>
                </p>
                <p class="w3-text w3-justify w3-large w3-margin-16">
                    Ambos frameworks tienen sus propias paginas (Hadoop y Spark), asi que son libres de instalar los dos en sus maquinas, sin embargo va a ser mas fácil que trabajen en las computadoras del laboratorio para completar este lab. Esten seguros de entender como funciona el framework de Spark bien, porque este es el que vamos a utilizar en el proyecto 2.
                    <br><br>
                    <strong>Eviten las Variables Globales</strong>
                    <br><br>
                    Cuando usen ya sea Hadoop o Spark, eviten utilizar variables globales! Esto arruina el propósito de tener múltiples tareas corriendo en paralelo y genera embotellamientos cuando múltiples tareas tratan de acceder a la variable global al mismo tiempo. Como resultado, la mayoría de algoritmos van a ser implementados sin usar variables globales.
                    <br><br>
                    <strong>Como correr Spark via command line</strong>
                    <br><br>
                    Para este laboratorio y en el proyecto les  vamos a proporcionar un Makefile para ayudarlos a correr sus  archivos de Spark, pero cuando usen Spark en algún otro lugar (Esperamos lo utilicen, DEBERIAN :P),  van a necesitar saber como correr Spark via command line. Solo necesitan correr el siguiente comando:
                </p>
<pre class="w3-code w3-light-grey notranslate">
    <span class="w3-text-teal">$</span> spark-submit xxx.py <span class="w3-text-grey"># Corrre el archivo de Spark xxx.py</span>
</pre>
                <p class="w3-text w3-justify w3-large w3-margin-16">
                    Si su archivo de spark toma argumentos, el comando es similar solo tienen que añadir cualesquiera argumentos que necesiten, así:
                </p>
<pre class="w3-code w3-light-grey notranslate">
    <span class="w3-text-teal">$</span> spark-submit xxx.py arg1 arg2<span class="w3-text-grey"> # Corre el archivo de Spark xxx.py y pasa los argumentos arg1 y arg2 a xxx.py</span>
</pre>
                <p class="w3-text w3-justify w3-large w3-margin-16">
                    Spark también incluye su interprete que corre con Python, y los va ayudar a testear cualesquiera de sus comandos de Spark.
                </p>
<pre class="w3-code w3-light-grey notranslate">
    <span class="w3-text-teal">$</span> pyspark <span class="w3-text-grey"># Corre el interprete de spark, prueben cualquier cosa aqui</span>
</pre>

                <p class="w3-text w3-justify w3-large w3-margin-16">
                    <strong>Spark Debbuging y algunos tips</strong><br><br>
                    Si alguna vez se encuentran preguntándose a ustedes mismos, porqué su output es raro o algo sale mal cuando corren sus archivos de Spark, recuerden estos tips:
                    <ul>
                        <li class="w3-large">Hagan uso de la funcion take, la función take puede correr en cualquier objeto RDD. Esta función toma un argumento N, que es un entero y  retorna los primeros N elementos que están dentro de su objeto RDD.</li>
                        <li class="w3-large">Pueden probar su funciones (map, reduce, etc.) dentro del interprete de Spark (pyspark, mencionado arriba). Simplemente importen su función que quieran probar en pyspark y van a ser capaces de correr la función y verificar si la salida es la que esperan. Aquí hay un pequeño ejemplo de wordcount.py:</li>
                    </ul>
                </p>
<pre class="w3-code w3-light-grey notranslate">
</pre>
            </div>
        </div>
        <footer class="w3-container w3-padding-32 w3-theme w3-center">
            <h2>CC3 - 2016</h2>
            <a class="w3-btn-floating w3-teal" href="https://slack.com/" title="SLACK"><i class="fa fa-slack"></i></a>
            <h4>Universidad Galileo</h4>
            <div style="position:relative;bottom:103px;z-index:1;" class="w3-tooltip w3-right">
                <a class="w3-btn w3-theme" href="#header"><span class="w3-xlarge">
                <i class="fa fa-chevron-circle-up"></i></span></a>
            </div>
        </footer>
    </body>
</html>
